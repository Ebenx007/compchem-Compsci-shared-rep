{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "data_Engineering_1.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "-ngN0JvNrVf1",
        "Vb0nhCZKsJZO"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ebenx007/compchem-Compsci-shared-rep/blob/main/2_Data_Preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQP7pmnVpNHU"
      },
      "source": [
        "from google.colab import drive\n",
        "from pathlib import Path\n",
        "import sys\n",
        "import os\n",
        "import shutil\n",
        "import tarfile\n",
        "import zipfile\n",
        "import subprocess\n",
        "import pickle\n",
        "import re\n",
        "import glob"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v24G22PeDBtU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4595009f-6294-4717-e1a9-dd72241cb73f"
      },
      "source": [
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Emc1UbhEEjn"
      },
      "source": [
        "\n",
        "[**1.Data-Acquisition is here**](https://github.com/Ebenx007/compchem-Compsci-shared-rep/blob/main/1_data_acquisition.ipynb)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53jpRwH3_eN0"
      },
      "source": [
        "# 2.   PROCESS & CURATE DATA FOR USE IN MODELS\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMqIBdOvp0dY"
      },
      "source": [
        "*   GENERATE GRAPHS FROM COMPILED CODE & BINARIES.\n",
        "---\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKI9cmh7tncA"
      },
      "source": [
        "\n",
        " >  * \n",
        "1.   Use pycparser to extract ASTs from C code and serialize C ASTs graphs \n",
        "2.   Serialize to Json files\n",
        "3.   Use Angr to extract CFG from C binaries\n",
        "4.   Archive processed data for use in Vector generation for ML models \n",
        "\n",
        "\n",
        "\n",
        "    Store Json graphs in Googledrive for use in generating vectors for the ML Models.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53yXZy3wRWra"
      },
      "source": [
        "**3.1 Using pycparser and Json serializing script to generate serialized ASTs from compilable Competition C code submissions** \n",
        "----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U0GR2dBxM8g6"
      },
      "source": [
        "> *   pycparser and Json serializing script for single file C programs submitted in programming competition "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Sm_Ep7PLqv6",
        "outputId": "e39dea18-ecb1-4837-abe1-f5656c62917b"
      },
      "source": [
        "%%writefile c_json.py\n",
        "\n",
        "# Original script from:\n",
        "#-----------------------------------------------------------------\n",
        "# pycparser: serialize_ast.py\n",
        "#\n",
        "# Simple example of serializing AST\n",
        "#\n",
        "# Hart Chu [https://github.com/CtheSky]\n",
        "# Eli Bendersky [https://eli.thegreenplace.net/]\n",
        "# License: BSD\n",
        "#-----------------------------------------------------------------\n",
        "## Adjusted for use here by Valentine Eben.\n",
        "\n",
        "import json\n",
        "import sys\n",
        "import re\n",
        "\n",
        "\n",
        "\n",
        "from pycparser import parse_file, c_ast\n",
        "from pycparser.plyparser import Coord\n",
        "\n",
        "\n",
        "RE_CHILD_ARRAY = re.compile(r'(.*)\\[(.*)\\]')\n",
        "RE_INTERNAL_ATTR = re.compile('__.*__')\n",
        "\n",
        "\n",
        "class CJsonError(Exception):\n",
        "    pass\n",
        "\n",
        "\n",
        "def memodict(fn):\n",
        "    \"\"\" Fast memoization decorator for a function taking a single argument \"\"\"\n",
        "    class memodict(dict):\n",
        "        def __missing__(self, key):\n",
        "            ret = self[key] = fn(key)\n",
        "            return ret\n",
        "    return memodict().__getitem__\n",
        "\n",
        "\n",
        "@memodict\n",
        "def child_attrs_of(klass):\n",
        "    \"\"\"\n",
        "    Given a Node class, get a set of child attrs.\n",
        "    Memoized to avoid highly repetitive string manipulation\n",
        "    \"\"\"\n",
        "    non_child_attrs = set(klass.attr_names)\n",
        "    all_attrs = set([i for i in klass.__slots__ if not RE_INTERNAL_ATTR.match(i)])\n",
        "    return all_attrs - non_child_attrs\n",
        "\n",
        "\n",
        "def to_dict(node):\n",
        "    \"\"\" Recursively convert an ast into dict representation. \"\"\"\n",
        "    klass = node.__class__\n",
        "\n",
        "    result = {}\n",
        "\n",
        "    # Metadata\n",
        "    result['_nodetype'] = klass.__name__\n",
        "\n",
        "    # Local node attributes\n",
        "    for attr in klass.attr_names:\n",
        "        result[attr] = getattr(node, attr)\n",
        "\n",
        "    # Coord object\n",
        "    if node.coord:\n",
        "        result['coord'] = str(node.coord)\n",
        "    else:\n",
        "        result['coord'] = None\n",
        "\n",
        "    # Child attributes\n",
        "    for child_name, child in node.children():\n",
        "        # Child strings are either simple (e.g. 'value') or arrays (e.g. 'block_items[1]')\n",
        "        match = RE_CHILD_ARRAY.match(child_name)\n",
        "        if match:\n",
        "            array_name, array_index = match.groups()\n",
        "            array_index = int(array_index)\n",
        "            # arrays come in order, so we verify and append.\n",
        "            result[array_name] = result.get(array_name, [])\n",
        "            if array_index != len(result[array_name]):\n",
        "                raise CJsonError('Internal ast error. Array {} out of order. '\n",
        "                    'Expected index {}, got {}'.format(\n",
        "                    array_name, len(result[array_name]), array_index))\n",
        "            result[array_name].append(to_dict(child))\n",
        "        else:\n",
        "            result[child_name] = to_dict(child)\n",
        "\n",
        "    # Any child attributes that were missing need \"None\" values in the json.\n",
        "    for child_attr in child_attrs_of(klass):\n",
        "        if child_attr not in result:\n",
        "            result[child_attr] = None\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "def to_json(node, **kwargs):\n",
        "    \"\"\" Convert ast node to json string \"\"\"\n",
        "    return json.dumps(to_dict(node), **kwargs)\n",
        "\n",
        "\n",
        "def file_to_dict(filename):\n",
        "    \"\"\" Load C file into dict representation of ast \"\"\"\n",
        "    ## ast = parse_file(filename, use_cpp=True) my addition of pycparser fakehead to allow for intraction with files\n",
        "    ast = parse_file(filename, use_cpp=True,\n",
        "            cpp_path='gcc',\n",
        "            cpp_args=['-E', r'-Iutils/fake_libc_include'])\n",
        "    return to_dict(ast)\n",
        "\n",
        "\n",
        "def file_to_json(filename, **kwargs):\n",
        "    \"\"\" Load C file into json string representation of ast \"\"\"\n",
        "     ## ast = parse_file(filename, use_cpp=True) my addition of pycparser fakehead to allow for intraction with files\n",
        "    ast = parse_file(filename, use_cpp=True,\n",
        "            cpp_path='gcc',\n",
        "            cpp_args=['-E', r'-Iutils/fake_libc_include'])\n",
        "    return to_json(ast, **kwargs)\n",
        "\n",
        "\n",
        "def _parse_coord(coord_str):\n",
        "    \"\"\" Parse coord string (file:line[:column]) into Coord object. \"\"\"\n",
        "    if coord_str is None:\n",
        "        return None\n",
        "\n",
        "    vals = coord_str.split(':')\n",
        "    vals.extend([None] * 3)\n",
        "    filename, line, column = vals[:3]\n",
        "    return Coord(filename, line, column)\n",
        "\n",
        "\n",
        "def _convert_to_obj(value):\n",
        "    \"\"\"\n",
        "    Convert an object in the dict representation into an object.\n",
        "    Note: Mutually recursive with from_dict.\n",
        "    \"\"\"\n",
        "    value_type = type(value)\n",
        "    if value_type == dict:\n",
        "        return from_dict(value)\n",
        "    elif value_type == list:\n",
        "        return [_convert_to_obj(item) for item in value]\n",
        "    else:\n",
        "        # String\n",
        "        return value\n",
        "\n",
        "\n",
        "def from_dict(node_dict):\n",
        "    \"\"\" Recursively build an ast from dict representation \"\"\"\n",
        "    class_name = node_dict.pop('_nodetype')\n",
        "\n",
        "    klass = getattr(c_ast, class_name)\n",
        "\n",
        "    # Create a new dict containing the key-value pairs which we can pass\n",
        "    # to node constructors.\n",
        "    objs = {}\n",
        "    for key, value in node_dict.items():\n",
        "        if key == 'coord':\n",
        "            objs[key] = _parse_coord(value)\n",
        "        else:\n",
        "            objs[key] = _convert_to_obj(value)\n",
        "\n",
        "    # Use keyword parameters, which works thanks to beautifully consistent\n",
        "    # ast Node initializers.\n",
        "    return klass(**objs)\n",
        "\n",
        "\n",
        "def from_json(ast_json):\n",
        "    \"\"\" Build an ast from json string representation \"\"\"\n",
        "    return from_dict(json.loads(ast_json))\n",
        "\n",
        "\n",
        "#------------------------------------------------------------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    if len(sys.argv) > 1:\n",
        "        # Some test code...\n",
        "        # Do trip from C -> ast -> dict -> ast -> json, then print.\n",
        "        ast_dict = file_to_dict(sys.argv[1])\n",
        "        ast = from_dict(ast_dict)\n",
        "        json_object = to_json(ast, sort_keys=True, indent=4)\n",
        "        print(json_object)\n",
        "        with open(sys.argv[1][:-2]+ \".json\", \"w\") as outfile:\n",
        "          outfile.write(json_object)\n",
        "        ## little adjustment to save to a file names almost as input file. The minus 2 for \".c\"\n",
        "    else:\n",
        "        print(\"Please provide a filename as argument\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing c_json.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p6NU1_H9SOyE",
        "outputId": "7e20e48b-1021-4d5a-bc80-c533582fa7c4"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C\t\t\t       juliet_dataset_CWE_testcases_paths_ls_file\n",
            "c_compiled_ls_file\t       juliet_dataset_ls_file\n",
            "c_json.py\t\t       Juliet_Test_Suite_v1.3_for_C_Cpp.zip\n",
            "cpp_compiled_ls_file\t       ProgramData\n",
            "decodable_submisisons_ls_file  programs.tar.gz\n",
            "drive\t\t\t       sample_data\n",
            "juliet_dataset_CWE_ls_file     submisisons_ls_file\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0Mo7L5mSZxE"
      },
      "source": [
        "#Test AST generating script \n",
        "!python3 c_json.py /content/ProgramData/1/1076.c"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r73PUbfTSo4i"
      },
      "source": [
        "#Check that json ast (1076.json) was created in addtion to the stdout priprint \n",
        "!ls ./ProgramData/1/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Rz0IxBATgTE",
        "outputId": "9b389d18-9e1d-4022-9734-ac3af4210a8b"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C\t\t\t       juliet_dataset_CWE_testcases_paths_ls_file\n",
            "c_compiled_ls_file\t       juliet_dataset_ls_file\n",
            "c_json.py\t\t       Juliet_Test_Suite_v1.3_for_C_Cpp.zip\n",
            "cpp_compiled_ls_file\t       ProgramData\n",
            "decodable_submisisons_ls_file  programs.tar.gz\n",
            "drive\t\t\t       sample_data\n",
            "juliet_dataset_CWE_ls_file     submisisons_ls_file\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_7_Wp5DUMl-",
        "outputId": "46fcbe02-13f6-43b6-b366-023e94694eb6"
      },
      "source": [
        "#Generate the rest of the json ASTs from the Programming Competition submissions \n",
        "for i in range(len(compiled_c_code)):\n",
        "    subprocess.run([\"python3\", \"c_json.py\", compiled_c_code[i]])\n",
        "print('Done generating json ASTs. Verify with ls cmd')  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done generating json ASTs.  Use list files to verify success\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAjYnMl8UrW2"
      },
      "source": [
        "#Verify success of json generating script\n",
        "programming_competition_c_ast_jsons = []\n",
        "paths = Path('./ProgramData').glob('**/*.json')\n",
        "for path in paths:\n",
        "  programming_competition_c_ast_jsons.append(str(path))\n",
        "  # str because path is an object not string\n",
        "print(\"Generated {} jsons of C ASTs from the programming submissions\".format(len(programming_competition_c_ast_jsons)))\n",
        "print(programming_competition_c_ast_jsons)\n",
        "print('\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_E4XS5SqVPtG"
      },
      "source": [
        "#check for json ASTs in  ProgramData subdirectories e.g. ProgramData/1/\n",
        "!ls ./ProgramData/1/ "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yq_6KNJGJCMc"
      },
      "source": [
        "with open('programming_competition_c_ast_jsons_ls_file', 'wb') as fp:\n",
        "  pickle.dump (programming_competition_c_ast_jsons, fp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_J-G-gxakvb"
      },
      "source": [
        "**3.2 Using pycparser and Json serializing script to generate serialized ASTs from juliet C code**\n",
        "---- "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DslBnkLsr0c3"
      },
      "source": [
        "##################### copy partially processed files for further processing ########### \n",
        "!cp \"/content/drive/My Drive/2020/Fall2020/individual_lab_members/ebenx007/phase1_processed_juliet_dataset.zip\" . "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yMm8iX2idvI7",
        "outputId": "d4b7a2bd-25a2-455a-e874-8643c05090c3"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C  drive  phase1_processed_juliet_dataset.zip  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J7j4-xQleAg7",
        "outputId": "4df2775f-6c18-42be-f86e-970a7d334fc4"
      },
      "source": [
        "with zipfile.ZipFile('phase1_processed_juliet_dataset.zip', 'r') as p_juliet_dataset:\n",
        "   p_juliet_dataset.extractall()\n",
        "   print('Done Extracting processed juliet dataset')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done Extracting processed juliet dataset\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xtknkvFceI1g",
        "outputId": "f50d7973-3ded-4bf7-ac6b-6554f91e7180"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C  drive  phase1_processed_juliet_dataset.zip  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zCjYO0xGcgR5",
        "outputId": "b42356eb-bc21-43cc-af13-4486591b9e0a"
      },
      "source": [
        "#cd cmd to directoy where files where saved before archived\n",
        "%cd C"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/C\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-4By-4L7HzY"
      },
      "source": [
        "#loading pickled data back CWE_makefile_dir\n",
        "CWE_makefile_dir = []\n",
        "with open(\"CWE_makefile_dir_ls_file\", \"rb\") as fld:\n",
        "  CWE_makefile_dir = pickle.load(fld)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iP27eIWtcmZo",
        "outputId": "b916b290-9739-4649-c6ee-4fb6449bca65"
      },
      "source": [
        "#change back to home dir\n",
        "%cd .."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJuU_s-38Aas"
      },
      "source": [
        "print(len(CWE_makefile_dir))\n",
        "print(CWE_makefile_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CtN3gUvfxMh8"
      },
      "source": [
        "> *   pycparser and Json serializing script for multi file programs "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gCrG-ydsQop",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64bf37c3-9acc-4dce-bf2f-35cbf39bf75e"
      },
      "source": [
        "#Start by cloneing pycparser to ease access to pycparser's Fakeheaders, needed for AST generation, instead of trying to access those that come with the pycpaser package. Eli's idea and it works  \n",
        "!git clone  https://github.com/eliben/pycparser.git \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'pycparser'...\n",
            "remote: Enumerating objects: 59, done.\u001b[K\n",
            "remote: Counting objects: 100% (59/59), done.\u001b[K\n",
            "remote: Compressing objects: 100% (38/38), done.\u001b[K\n",
            "remote: Total 2548 (delta 25), reused 38 (delta 13), pack-reused 2489\u001b[K\n",
            "Receiving objects: 100% (2548/2548), 1.15 MiB | 2.90 MiB/s, done.\n",
            "Resolving deltas: 100% (1702/1702), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFZ8B8o3x96f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b5c4e28-224d-4a45-fe50-6fb46ba2474f"
      },
      "source": [
        "%%writefile multi_file_c_json.py\n",
        "\n",
        "# Original script from:\n",
        "#-----------------------------------------------------------------\n",
        "# pycparser: serialize_ast.py\n",
        "#\n",
        "# Simple example of serializing AST\n",
        "#\n",
        "# Hart Chu [https://github.com/CtheSky]\n",
        "# Eli Bendersky [https://eli.thegreenplace.net/]\n",
        "# License: BSD\n",
        "#-----------------------------------------------------------------\n",
        "## Adjusted for use here by Valentine Eben notice the addtion of the headers for this specific juliet dataset as '-Icontent/C'.\n",
        "\n",
        "import json\n",
        "import sys\n",
        "import re\n",
        "\n",
        "\n",
        "from pycparser import parse_file, c_ast\n",
        "from pycparser.plyparser import Coord\n",
        "\n",
        "\n",
        "RE_CHILD_ARRAY = re.compile(r'(.*)\\[(.*)\\]')\n",
        "RE_INTERNAL_ATTR = re.compile('__.*__')\n",
        "\n",
        "\n",
        "class CJsonError(Exception):\n",
        "    pass\n",
        "\n",
        "\n",
        "def memodict(fn):\n",
        "    \"\"\" Fast memoization decorator for a function taking a single argument \"\"\"\n",
        "    class memodict(dict):\n",
        "        def __missing__(self, key):\n",
        "            ret = self[key] = fn(key)\n",
        "            return ret\n",
        "    return memodict().__getitem__\n",
        "\n",
        "\n",
        "@memodict\n",
        "def child_attrs_of(klass):\n",
        "    \"\"\"\n",
        "    Given a Node class, get a set of child attrs.\n",
        "    Memoized to avoid highly repetitive string manipulation\n",
        "    \"\"\"\n",
        "    non_child_attrs = set(klass.attr_names)\n",
        "    all_attrs = set([i for i in klass.__slots__ if not RE_INTERNAL_ATTR.match(i)])\n",
        "    return all_attrs - non_child_attrs\n",
        "\n",
        "\n",
        "def to_dict(node):\n",
        "    \"\"\" Recursively convert an ast into dict representation. \"\"\"\n",
        "    klass = node.__class__\n",
        "\n",
        "    result = {}\n",
        "\n",
        "    # Metadata\n",
        "    result['_nodetype'] = klass.__name__\n",
        "\n",
        "    # Local node attributes\n",
        "    for attr in klass.attr_names:\n",
        "        result[attr] = getattr(node, attr)\n",
        "\n",
        "    # Coord object\n",
        "    if node.coord:\n",
        "        result['coord'] = str(node.coord)\n",
        "    else:\n",
        "        result['coord'] = None\n",
        "\n",
        "    # Child attributes\n",
        "    for child_name, child in node.children():\n",
        "        # Child strings are either simple (e.g. 'value') or arrays (e.g. 'block_items[1]')\n",
        "        match = RE_CHILD_ARRAY.match(child_name)\n",
        "        if match:\n",
        "            array_name, array_index = match.groups()\n",
        "            array_index = int(array_index)\n",
        "            # arrays come in order, so we verify and append.\n",
        "            result[array_name] = result.get(array_name, [])\n",
        "            if array_index != len(result[array_name]):\n",
        "                raise CJsonError('Internal ast error. Array {} out of order. '\n",
        "                    'Expected index {}, got {}'.format(\n",
        "                    array_name, len(result[array_name]), array_index))\n",
        "            result[array_name].append(to_dict(child))\n",
        "        else:\n",
        "            result[child_name] = to_dict(child)\n",
        "\n",
        "    # Any child attributes that were missing need \"None\" values in the json.\n",
        "    for child_attr in child_attrs_of(klass):\n",
        "        if child_attr not in result:\n",
        "            result[child_attr] = None\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "def to_json(node, **kwargs):\n",
        "    \"\"\" Convert ast node to json string \"\"\"\n",
        "    return json.dumps(to_dict(node), **kwargs)\n",
        "\n",
        "\n",
        "def file_to_dict(filename):\n",
        "    \"\"\" Load C file into dict representation of ast \"\"\"\n",
        "     ## ast = parse_file(filename, use_cpp=True) my addition of pycparser fakehead to allow for intraction with files.\n",
        "    ast = parse_file(filename, use_cpp=True,\n",
        "            cpp_path='gcc',\n",
        "            cpp_args=['-nostdinc','-E','-IC/testcasesupport/', r'-Ipycparser/utils/fake_libc_include'])\n",
        "    ## also -nostdinc to supress hard coded system headers creating issues and adding the std for this project \n",
        "    return to_dict(ast)\n",
        "\n",
        "\n",
        "def file_to_json(filename, **kwargs):\n",
        "    \"\"\" Load C file into json string representation of ast \"\"\"\n",
        "     ## ast = parse_file(filename, use_cpp=True) my addition of pycparser fakehead to allow for intraction with files.\n",
        "    ast = parse_file(filename, use_cpp=True,\n",
        "            cpp_path='gcc',\n",
        "            cpp_args=['-nostdinc','-E','-IC/testcasesupport/', r'-Ipycparser/utils/fake_libc_include'])\n",
        "   ## also -nostdinc to supress hard coded system headers creating issues\n",
        "    return to_json(ast, **kwargs)\n",
        "\n",
        "\n",
        "def _parse_coord(coord_str):\n",
        "    \"\"\" Parse coord string (file:line[:column]) into Coord object. \"\"\"\n",
        "    if coord_str is None:\n",
        "        return None\n",
        "\n",
        "    vals = coord_str.split(':')\n",
        "    vals.extend([None] * 3)\n",
        "    filename, line, column = vals[:3]\n",
        "    return Coord(filename, line, column)\n",
        "\n",
        "\n",
        "def _convert_to_obj(value):\n",
        "    \"\"\"\n",
        "    Convert an object in the dict representation into an object.\n",
        "    Note: Mutually recursive with from_dict.\n",
        "    \"\"\"\n",
        "    value_type = type(value)\n",
        "    if value_type == dict:\n",
        "        return from_dict(value)\n",
        "    elif value_type == list:\n",
        "        return [_convert_to_obj(item) for item in value]\n",
        "    else:\n",
        "        # String\n",
        "        return value\n",
        "\n",
        "\n",
        "def from_dict(node_dict):\n",
        "    \"\"\" Recursively build an ast from dict representation \"\"\"\n",
        "    class_name = node_dict.pop('_nodetype')\n",
        "\n",
        "    klass = getattr(c_ast, class_name)\n",
        "\n",
        "    # Create a new dict containing the key-value pairs which we can pass\n",
        "    # to node constructors.\n",
        "    objs = {}\n",
        "    for key, value in node_dict.items():\n",
        "        if key == 'coord':\n",
        "            objs[key] = _parse_coord(value)\n",
        "        else:\n",
        "            objs[key] = _convert_to_obj(value)\n",
        "\n",
        "    # Use keyword parameters, which works thanks to beautifully consistent\n",
        "    # ast Node initializers.\n",
        "    return klass(**objs)\n",
        "\n",
        "\n",
        "def from_json(ast_json):\n",
        "    \"\"\" Build an ast from json string representation \"\"\"\n",
        "    return from_dict(json.loads(ast_json))\n",
        "\n",
        "\n",
        "#------------------------------------------------------------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    if len(sys.argv) > 1:\n",
        "        # Some test code...\n",
        "        # Do trip from C -> ast -> dict -> ast -> json, then print.\n",
        "        ast_dict = file_to_dict(sys.argv[1])\n",
        "        ast = from_dict(ast_dict)\n",
        "        json_object = to_json(ast, sort_keys=True, indent=4)\n",
        "        print(json_object)\n",
        "        with open(sys.argv[1][:-2]+ \".json\", \"w\") as outfile:\n",
        "          outfile.write(json_object)\n",
        "        ## little adjustment to save to a file names almost as input file. The minus 2 for \".c\"\n",
        "    else:\n",
        "        print(\"Please provide a filename as argument\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing multi_file_c_json.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UO9H5y4EyYqQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7cb72efd-ed11-4e81-fd6d-5cc0af7a0e93"
      },
      "source": [
        "#check script was created\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C      multi_file_c_json.py\t\t    pycparser\n",
            "drive  phase1_processed_juliet_dataset.zip  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijkigoz2ybDl"
      },
      "source": [
        "#Test multiple file C program Json Genrating script\n",
        "!python3 multi_file_c_json.py C/testcases/CWE675_Duplicate_Operations_on_Resource/CWE675_Duplicate_Operations_on_Resource__fopen_52a.c"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsS6lAr8y6Or",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6acd93b-3a58-497d-d1dc-102abc6529ff"
      },
      "source": [
        "#cd to check creation of json AST (C/testcases/CWE675_Duplicate_Operations_on_Resource/CWE675_Duplicate_Operations_on_Resource__fopen_52a.json )\n",
        "%cd C/testcases/CWE675_Duplicate_Operations_on_Resource/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/C/testcases/CWE675_Duplicate_Operations_on_Resource\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBLFeJHWzLA7"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gzZdRYaZdKCI",
        "outputId": "32b55802-940b-49fc-d959-2d3e56ccad81"
      },
      "source": [
        "#back to home dir from which path begins\n",
        "%cd .."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svznzWSwyDZz"
      },
      "source": [
        "#Create list of all compiled juliet code along with c and cpp compiled code for easy parsing with appropriate tools\n",
        "\n",
        "\n",
        "compilable_juliet_code = []\n",
        "compilable_juliet_c_code = []\n",
        "compilable_juliet_cpp_code = []\n",
        "paths = Path('./C/testcases').glob('**/*.o')\n",
        "for path in paths:\n",
        "  if re.search(r'CWE',str(path.name)):\n",
        "    #.name to make sure the last part of the name i.e. before the suffix is verified\n",
        "    compilable_juliet_code.append(str(path))\n",
        "    if Path(str(path)[:-2]+'.c').exists():\n",
        "      #Back to Path allows you to use the .exists atribute, while str allows -2 for \".o\" and + operator for +'.c'\n",
        "      compilable_juliet_c_code.append(str(path)[:-2]+'.c')\n",
        "    if Path(str(path)[:-2]+'.cpp').exists():\n",
        "      compilable_juliet_cpp_code.append(str(path)[:-2]+'.cpp')\n",
        " \n",
        "  # str because path is an object not string\n",
        "print(\"Total of {} compilable code:\".format(len(compilable_juliet_code)))\n",
        "print(compilable_juliet_code[0])\n",
        "print(\"\\n{} of the compilable Juliet code is C:\".format(len(compilable_juliet_c_code)))\n",
        "print(compilable_juliet_c_code[0])\n",
        "print(\"\\n{} of the compilable Juliet code is C++:\".format(len(compilable_juliet_cpp_code)))\n",
        "print(compilable_juliet_cpp_code[0])\n",
        "print('\\n35551 + 30441 = {} matching the total compilable code in the Juliet dataset'.format(35551 + 30441))\n",
        "print('\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TjFi_lsdQB-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efaeef28-cf98-47d9-8547-043a7d4f2251"
      },
      "source": [
        "#Generate the rest of the json ASTs from the Juliet Dataset \n",
        "for i in range(len(compilable_juliet_c_code)):\n",
        "    subprocess.run([\"python3\", \"multi_file_c_json.py\", compilable_juliet_c_code[i]])\n",
        "print('Done generating Juliet C json ASTs.  Verify with ls cmd')  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done generating Juliet C json ASTs.  Verify with ls cmd\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PV4ykDHv_s9T",
        "outputId": "2b31e1df-556e-450e-cace-195ebc652c2d"
      },
      "source": [
        "#cd to testcases and use cmd ls to very presence of json ASTs\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C      multi_file_c_json.py\t\t    pycparser\n",
            "drive  phase1_processed_juliet_dataset.zip  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4g1zjvUsh8Pf",
        "outputId": "e5543672-11fc-4be5-aa7f-11e7bfe00148"
      },
      "source": [
        "%cd C/testcases/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/C/testcases\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3EJbKwhiFi7"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkOGp4ISizGE"
      },
      "source": [
        "print(CWE_makefile_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXKfngYii1SI"
      },
      "source": [
        "%cd CWE484_Omitted_Break_Statement_in_Switch/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTaILvaAjAm5"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3sJ5QDljGdK",
        "outputId": "4de6130e-545b-4adb-a6bd-af72e5ca6182"
      },
      "source": [
        "%cd .."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/C/testcases\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYi3bmAhjRKV"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_TxRjIAnjVtY",
        "outputId": "0b9303c0-1b10-411a-b06e-16ebf217884c"
      },
      "source": [
        "%cd CWE124_Buffer_Underwrite/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/C/testcases/CWE124_Buffer_Underwrite\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M7bfpxPpjeEP",
        "outputId": "43488bb2-b019-42df-a678-5f0670ef23b7"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "s01  s02  s03  s04\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VjdL0jbHjg3N",
        "outputId": "68a3356e-872f-4f40-b181-83369592ea57"
      },
      "source": [
        "%cd s01/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/C/testcases/CWE124_Buffer_Underwrite/s01\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LeIYkC_sjlUh"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5CuzmBCLjstr",
        "outputId": "1cf85597-5348-438e-d7dc-20018ca18fc0"
      },
      "source": [
        "%cd .."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WoFkwaUpz5vd"
      },
      "source": [
        "#create a list of the Juliet C Json ASTs\n",
        "juliet_c_ast_jsons = []\n",
        "juliet_json_paths = Path('./C/testcases').glob('**/*.json')\n",
        "for path in juliet_json_paths:\n",
        "  juliet_c_ast_jsons.append(str(path))\n",
        "  # str because path is an object not string\n",
        "print(\"{} jsons of C ASTs from the programming submissions:\".format(len(juliet_c_ast_jsons)))\n",
        "print(juliet_c_ast_jsons[0])\n",
        "print('\\n')   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwsdap5sGNKa"
      },
      "source": [
        "with open('compilable_juliet_code_ls_file', 'wb') as fp:\n",
        "  pickle.dump (compilable_juliet_code, fp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87gvKDQOGTTs"
      },
      "source": [
        "with open('compilable_juliet_c_code_ls_file', 'wb') as fp:\n",
        "  pickle.dump (compilable_juliet_c_code, fp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwItwXS0IfYL"
      },
      "source": [
        "with open('compilable_juliet_cpp_code_ls_file', 'wb') as fp:\n",
        "  pickle.dump (compilable_juliet_cpp_code, fp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5A3inCGGUmQ"
      },
      "source": [
        "with open('juliet_c_ast_jsons_ls_file', 'wb') as fp:\n",
        "  pickle.dump (juliet_c_ast_jsons, fp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KXS_LYIJkIXB",
        "outputId": "6a0a39b2-c2f4-48e5-c62b-ace60241604a"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C\t\t\t\t    juliet_c_ast_jsons_ls_file\n",
            "compilable_juliet_c_code_ls_file    multi_file_c_json.py\n",
            "compilable_juliet_code_ls_file\t    phase1_processed_juliet_dataset.zip\n",
            "compilable_juliet_cpp_code_ls_file  pycparser\n",
            "drive\t\t\t\t    sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDAPk0nl22o3"
      },
      "source": [
        "    Curating the compiled files and metadata for further processing and use in  building models     "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubcakhe_bVri"
      },
      "source": [
        "**3.3 Curating processed Programming Competition submissions** \n",
        "----"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WoH84Xwi-7Of"
      },
      "source": [
        "#move pickled metadata file into folders for compression and curating for PHASE 2 of Big Data Cleaning Pipelne\n",
        "%cp decodable_submisisons_ls_file submisisons_ls_file cpp_compiled_ls_file c_compiled_ls_file programming_competition_c_ast_jsons_ls_file c_json.py ProgramData/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "0IBNaCJLEUXM",
        "outputId": "1555a6d2-c586-4eeb-e571-711be51db00c"
      },
      "source": [
        "#Creating tar archive of processed Progamming competion dataset and metadata \n",
        "shutil.make_archive('phase1_programing_competition','tar','/content/','ProgramData')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/phase1_programing_competition.tar'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNcB2B30n7Au"
      },
      "source": [
        "#Verify tarball of processed files\n",
        "check_processed_archive = []\n",
        "with tarfile.open('phase1_programing_competition.tar', 'r') as submissions:\n",
        "  for member in submissions:\n",
        "    if member.isdir() and member.name.count ('/') > 0:\n",
        "     # The '/' > 0 is to ensure the root directory is ignored \n",
        "       print(member.name) \n",
        "    if member.isfile():\n",
        "     check_processed_archive.append (member.name)\n",
        "print(\"\\n Number of files in tarball for export {0}\".format(len(check_processed_archive)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOVPklqEzuIb"
      },
      "source": [
        "!cp phase1_programing_competition.tar \"/content/drive/My Drive/2020/Fall2020/individual_lab_members/ebenx007/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ZMZVrOpb7FV"
      },
      "source": [
        "**3.4 Curating processed juliet source code** \n",
        "----"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oerfJfqP5Bkg",
        "outputId": "eb8f9e0e-0576-4df0-abc8-cd4e5c19a882"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C\t\t\t\t    juliet_c_ast_jsons_ls_file\n",
            "compilable_juliet_c_code_ls_file    multi_file_c_json.py\n",
            "compilable_juliet_code_ls_file\t    phase1_processed_juliet_dataset.zip\n",
            "compilable_juliet_cpp_code_ls_file  pycparser\n",
            "drive\t\t\t\t    sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIlI_Di9kzNM"
      },
      "source": [
        "#Copy of files processed on Dec 3, 2020 \n",
        "%cp -r compilable_juliet_code_ls_file compilable_juliet_c_code_ls_file compilable_juliet_cpp_code_ls_file juliet_c_ast_jsons_ls_file multi_file_c_json.py pycparser/  /content/C/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlP8t4aw9S47"
      },
      "source": [
        "#NOT DONE move pickled metadata file into folders for compression and curating for PHASE 2 of Big Data Cleaning Pipelne NOT DONE\n",
        "%cp juliet_dataset_CWE_testcases_paths_ls_file juliet_dataset_CWE_ls_file juliet_dataset_ls_file CWE_makefile_dir_ls_file /content/C/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "HogebfPWU-MA",
        "outputId": "caadf605-97cc-4a25-c319-232bcdafe10e"
      },
      "source": [
        "#zipping processed juliet dataset and metadata\n",
        "shutil.make_archive('curated_processed_juliet_dataset','zip','/content/','C')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/curated_processed_juliet_dataset.zip'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNWjE_sJ0BMI"
      },
      "source": [
        "#Verify zipped archive of processed juliet dataset\n",
        "processed_juliet_dataset_ls = []\n",
        "with zipfile.ZipFile('curated_processed_juliet_dataset.zip', 'r') as jz:\n",
        "  for member in jz.namelist():\n",
        "    if member.endswith('/') and member.count('/') > 2:\n",
        "      # > 2  '/' count to ignore none testcases related directories in the archive\n",
        "      print( member)  \n",
        "    if (not member.endswith('/')) and member.count('/') > 2:\n",
        "      # > 2 '/' count to append to list only files in testcases directories, ignoring files inthe root directory  \n",
        "      processed_juliet_dataset_ls.append(member)\n",
        "    processed_juliet_dataset_ls.append(member) \n",
        "print(\"Number of processed Juliet C/C++ test files and metadata {0}\".format(len(processed_juliet_dataset_ls)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iX_8-VHC1ex7"
      },
      "source": [
        "!cp curated_processed_juliet_dataset.zip \"/content/drive/My Drive/2020/Fall2020/individual_lab_members/ebenx007/\""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}