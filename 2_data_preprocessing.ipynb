{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2_data_preprocessing.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "-ngN0JvNrVf1",
        "Vb0nhCZKsJZO"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ebenx007/compchem-Compsci-shared-rep/blob/main/2_data_preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQP7pmnVpNHU"
      },
      "source": [
        "from google.colab import drive\n",
        "from pathlib import Path\n",
        "import sys\n",
        "import os\n",
        "import shutil\n",
        "import tarfile\n",
        "import zipfile\n",
        "import subprocess\n",
        "import pickle\n",
        "import re\n",
        "import glob"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v24G22PeDBtU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85c4a720-7779-4117-bf48-5df59d95d1bb"
      },
      "source": [
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2eg0S2SDJ9_O"
      },
      "source": [
        "#   RESTORE RAW DATA FROM [DATA AQUISITION DIRECTORY](https://github.com/Ebenx007/compchem-Compsci-shared-rep/blob/main/1_data_acquisition.ipynb)\n",
        "---\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bC5Q9oLVCFhq"
      },
      "source": [
        "#Load pickled metadata\n",
        "def load_data(file):\n",
        " with open(file,\"rb\") as f:\n",
        "   data = pickle.load(f)\n",
        " return(data)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bF8kEvuu2NbB"
      },
      "source": [
        "!cp \"/content/drive/My Drive/colab_root/compchem-compsci-shared-rep/raw/raw_data.tar\" ."
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccKdM3ZZJPuP"
      },
      "source": [
        "with tarfile.open('raw_data.tar', 'r') as f:\n",
        "  f.extractall()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5g3aq5dgQrQ"
      },
      "source": [
        "#copy raw_data and metadata into pwd \n",
        "%cp -r /content/data_acquisition/* ."
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kh471KPn0pOd",
        "outputId": "cbc39905-bac5-4a26-964e-09178f7a48c3"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data_acquisition\t\t\t   ProgramData\n",
            "drive\t\t\t\t\t   programs.tar.gz\n",
            "juliet_dataset_CWE_ls.pkl\t\t   raw_data.tar\n",
            "juliet_dataset_CWE_testcases_paths_ls.pkl  sample_data\n",
            "juliet_dataset_ls.pkl\t\t\t   submissions_ls.pkl\n",
            "Juliet_Test_Suite_v1.3_for_C_Cpp.zip\t   submissions_tasks_ls.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53jpRwH3_eN0"
      },
      "source": [
        "# 2.  DATA PREPROCESSING \n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUqRViecEGSZ"
      },
      "source": [
        "##2.1 Clean Main Dataset:\n",
        "\n",
        "*   Remove Uncompilable Source Code (platform: colab(linux))\n",
        "*   Remove Non UTF8 decodable entries\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tVBdjf1MTQu9",
        "outputId": "748cee14-d651-4ab3-b985-8cebcc68aef0"
      },
      "source": [
        "active_dir = '/content/ProgramData/'\n",
        "test_file_counter = 0\n",
        "for path, subdirs, files in os.walk(active_dir):\n",
        "    for name in files:\n",
        "      test_file_counter +=1\n",
        "print(\"{} files extracted from Programming Competition Submissions archive. \".format(test_file_counter))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "52000 files extracted from Programming Competition Submissions archive. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDveBPVNWc9i"
      },
      "source": [
        "#Variables to hold Meta Data from programming competition dataset preprocessing \n",
        "utf8_decodable_submisisons = []\n",
        "utf8_undecodable_submissions = []\n",
        "compiled_cpp_code = []\n",
        "compiled_c_code = []\n",
        "uncompilable_utf8_decodable_submissions = []"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m2De2t929KI2"
      },
      "source": [
        "> * Extract contents of .txt files submitted for Programming Competitions, convert to .cpp or .c files, and compile."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "og1CDBZAM0Lt"
      },
      "source": [
        "submissions_ls = load_data('submissions_ls.pkl')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8E44YSxx1Pi0"
      },
      "source": [
        "###2.1.1 Exploration: Clean/Compile 10 samples from Main Dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B1eILUFgOwW5",
        "outputId": "6ccdcc49-e1b3-4420-95ea-ec8737e89add"
      },
      "source": [
        "# 10 Sample to test extraction, conversion and compiling code  \n",
        "cpp_distinguishing_features = ['.cpp','cin','cout']\n",
        "for i in range(10):\n",
        "  with open(os.path.join('', submissions_ls[i]), 'r') as f:\n",
        "    try:\n",
        "      file_content = f.read()\n",
        "    except:\n",
        "       pass \n",
        "    if any(x in file_content for x in cpp_distinguishing_features):\n",
        "      new_cpp_filename = submissions_ls[i][:-4] + \".cpp\" \n",
        "      # the -4 for the .txt\n",
        "      with open(os.path.join('', new_cpp_filename), 'w') as fp:\n",
        "        cppheader= '''\n",
        "        #include<iostream> \n",
        "        #include <math.h>\n",
        "        using namespace std;\n",
        "        '''\n",
        "        fp.write(cppheader)\n",
        "        fp.write(file_content)\n",
        "      subprocess.call([\"g++\", new_cpp_filename, \"-o\", submissions_ls[i][:-4] + '.cppout',\"-std=c++11\", '-w', '-Ofast'])\n",
        "      print(new_cpp_filename)\n",
        "\n",
        "    else:\n",
        "      new_c_filename = submissions_ls[i][:-4] + \".c\"\n",
        "      with open(os.path.join('', new_c_filename), 'w') as fp:\n",
        "        fp.write(file_content)\n",
        "      subprocess.call([\"gcc\", new_c_filename, \"-o\"+submissions_ls[i][:-4] + '.out',\"-std=c99\", '-w', '-Ofast'])\n",
        "      print(new_c_filename)\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ProgramData/1/397.cpp\n",
            "ProgramData/1/147.cpp\n",
            "ProgramData/1/131.cpp\n",
            "ProgramData/1/1076.c\n",
            "ProgramData/1/2272.cpp\n",
            "ProgramData/1/703.cpp\n",
            "ProgramData/1/2063.c\n",
            "ProgramData/1/1892.c\n",
            "ProgramData/1/889.cpp\n",
            "ProgramData/1/1342.cpp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3K3sE4OFW1RJ"
      },
      "source": [
        "#Exploration \n",
        "!ls ./ProgramData/1/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jMmzyjg5MJHT"
      },
      "source": [
        "#Extract convert and compile the rest of the submissions\n",
        "cpp_distinguishing_features = ['.cpp','cin','cout']\n",
        "print('Compiling the rest of the submitted code ...')\n",
        "for i in range(len(submissions_ls)):\n",
        "  with open(os.path.join('', submissions_ls[i]), 'r') as f:\n",
        "    try:\n",
        "      file_content = f.read()\n",
        "      utf8_decodable_submisisons.append(submissions_ls[i])\n",
        "    except:\n",
        "       utf8_undecodable_submissions.append(submissions_ls[i])\n",
        "    if any(x in file_content for x in cpp_distinguishing_features):\n",
        "      new_cpp_filename = submissions_ls[i][:-4] + \".cpp\"\n",
        "      with open(os.path.join('', new_cpp_filename), 'w') as fp:\n",
        "        cppheader= '''\n",
        "        #include<iostream> \n",
        "        #include <math.h>\n",
        "        using namespace std;\n",
        "        '''\n",
        "        fp.write(cppheader)\n",
        "        fp.write(file_content)\n",
        "      subprocess.call([\"g++\", new_cpp_filename, \"-o\", submissions_ls[i][:-4] + '.cppout',\"-std=c++11\", '-w', '-Ofast'])\n",
        "      compiled_cpp_code.append(new_cpp_filename)\n",
        "  \n",
        "\n",
        "    else:\n",
        "      new_c_filename = submissions_ls[i][:-4] + \".c\"\n",
        "      with open(os.path.join('', new_c_filename), 'w') as fp:\n",
        "        fp.write(file_content)\n",
        "      subprocess.call([\"gcc\", new_c_filename, \"-o\"+submissions_ls[i][:-4] + '.out',\"-std=c99\", '-w', '-Ofast'])\n",
        "      compiled_c_code.append(new_c_filename)\n",
        "print('...' )\n",
        "print('Code compilation completed')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbkVCl95HVio"
      },
      "source": [
        "#Exploration\n",
        "!ls ./ProgramData/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKTMUCq22UdA"
      },
      "source": [
        "#Exploration\n",
        "!ls ./ProgramData/104"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WBdyQCWYjIui",
        "outputId": "d2c4bd62-f150-4703-e609-37606000d9af"
      },
      "source": [
        "#Exploration\n",
        "print(\"Overview of programming Competition dataset\")\n",
        "print(\"\\n Source code submissions {0}\".format(len(submissions_ls)))\n",
        "print(\"\\n Utf8 Decodable.txt files directories in dataset {0}\".format(len(utf8_decodable_submisisons)))\n",
        "print(\"\\n Utf8 Undecodable .txt files in dataset {0}\".format(len(utf8_undecodable_submissions)))\n",
        "print(\"\\n Compiled .cpp files in dataset {0}\".format(len(compiled_cpp_code)))\n",
        "print(\"\\n Compiled .c files in dataset {0}\".format(len(compiled_c_code)))\n",
        "print(\"\\n Uncompilable utf8 decodable files in dataset {0}\".format(len(uncompilable_utf8_decodable_submissions)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overview of programming Competition dataset\n",
            "\n",
            " Source code submissions 52000\n",
            "\n",
            " Utf8 Decodable.txt files directories in dataset 51752\n",
            "\n",
            " Utf8 Undecodable .txt files in dataset 248\n",
            "\n",
            " Compiled .cpp files in dataset 15406\n",
            "\n",
            " Compiled .c files in dataset 36594\n",
            "\n",
            " Uncompilable utf8 decodable files in dataset 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RfgaSf4yb-Ql",
        "outputId": "f1a38cce-1a46-44fe-918d-67721322ada8"
      },
      "source": [
        "print('Number of Compiled C code files and visual of List')\n",
        "print(len(compiled_c_code))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Compiled C code files and visual of List\n",
            "36594\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xipns3ZAGUGB"
      },
      "source": [
        "#Exploration\n",
        "print(compiled_c_code)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YzzJpjeT8tJP",
        "outputId": "f28a5d4e-e831-423c-9084-6b4697a969da"
      },
      "source": [
        "print('Number of Compiled C++ code files and visual of List')\n",
        "print(len(compiled_cpp_code))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Compiled C++ code files and visual of List\n",
            "15406\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c39RG9L6GZvo"
      },
      "source": [
        "print(compiled_cpp_code)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmV_gbNzGxAU"
      },
      "source": [
        "\n",
        "> *  Pickle Competition Dataset metadata for later use"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDtj8-ppbFtt"
      },
      "source": [
        "with open('cpp_compiled_ls.pkl', 'wb') as fp:\n",
        "  pickle.dump (compiled_cpp_code, fp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSaPQCMa8mQK"
      },
      "source": [
        "with open('submissions_ls.pkl', 'wb') as fp:\n",
        "  pickle.dump (submissions_ls, fp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGUMh5PrCeJc"
      },
      "source": [
        "with open('decodable_submisisons_ls.pkl', 'wb') as fp:\n",
        "  pickle.dump (utf8_decodable_submisisons, fp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v38aTlxLcEyH"
      },
      "source": [
        "with open('c_compiled_ls.pkl', 'wb') as fp:\n",
        "  pickle.dump (compiled_c_code, fp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tU0m1vZ9FWLJ"
      },
      "source": [
        "##2.2 Clean New Dataset:\n",
        "\n",
        "*   Remove Uncompilable Source Code (platform: colab(linux))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQI49d-pymsC"
      },
      "source": [
        "> *   Extract files from Juliet C/C++ test suite "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQ3ngQNAA2y3",
        "outputId": "3f24f814-16ef-48af-a1ed-8a11659b7536"
      },
      "source": [
        "with zipfile.ZipFile('Juliet_Test_Suite_v1.3_for_C_Cpp.zip', 'r') as juliet_dataset:\n",
        "   juliet_dataset.extractall()\n",
        "   print('Done Extracting dataset')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done Extracting dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YyVgRWo8lUXk",
        "outputId": "92c9d716-b93a-4fa7-b67f-b8646449e278"
      },
      "source": [
        "#View of extracted Juliet_dataset directory\n",
        "!ls /content/C"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "compile_all.bat\t\t py_common.py\n",
            "create_per_cwe_files.py  run_analysis_example_tool.py\n",
            "doc\t\t\t testcases\n",
            "Makefile\t\t testcasesupport\n",
            "manifest.xml\t\t update_main_cpp_and_testcases_h.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EK5ARGlZzvEJ",
        "outputId": "4f8a81e3-0f0d-48a7-c215-2a525be9f09f"
      },
      "source": [
        "#Check number of code files i.e. size of dataset\n",
        "juliet_code_files_dir = '/content/C/testcases/'\n",
        "test_file_counter = 0\n",
        "for path, subdirs, files in os.walk(juliet_code_files_dir):\n",
        "    for name in files:\n",
        "      test_file_counter +=1\n",
        "print(\"{} files in unzipped Juliet archive. Matches our earlier metadata overview with zipFILE module of 106075 source code files\".format(test_file_counter))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "106075 files in unzipped Juliet archive. Matches our earlier metadata overview with zipFILE module of 106075 source code files\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmB_ODR-L2cW"
      },
      "source": [
        "juliet_dataset_ls = load_data('juliet_dataset_ls.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mq_UCR3lfOXm"
      },
      "source": [
        "#Compilating CWE IDed compilable/makeFile-containing CWE IDed directories \n",
        "CWE_makefile_dir = []\n",
        "cwd = os.getcwd()\n",
        "print(\"Compiling ...\")\n",
        "for i in range(len(juliet_dataset_ls)):\n",
        "  if juliet_dataset_ls[i].endswith('Makefile') and 'CWE' in juliet_dataset_ls[i]:\n",
        "    CWE_makefile_dir.append(juliet_dataset_ls[i])\n",
        "    redx = re.findall(r'\\bCWE\\w.*', juliet_dataset_ls[i])\n",
        "    os.chdir(os.path.dirname(juliet_dataset_ls[i])) \n",
        "    print(redx[0][:-8]) \n",
        "    #Minus 8 for the length of the word Makefile leading to Makefile containing directories which are the only linun compilables\n",
        "    with open(os.path.join(cwd, os.path.dirname(juliet_dataset_ls[i]),'compilation.log'), 'w') as lg:\n",
        "      subprocess.run([\"make\", \"stdout=lg\"])\n",
        "    os.chdir(cwd)\n",
        "\n",
        "#152 individual CWE IDed dire with Makefiles\n",
        "print(\"Compilated all {} Makefile containing CWE IDed directories\".format(len(CWE_makefile_dir)))\n",
        "print('\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sAS1daflGQqZ"
      },
      "source": [
        "###2.2.1 Explore Partially processed New Dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWfXLh_QPsX5",
        "outputId": "d0f47dd6-1a79-4ec2-ef39-bd3b889617c9"
      },
      "source": [
        "print('Number of CWE IDed Makefiles and visualize in a List')\n",
        "print(len(CWE_makefile_dir))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of CWE IDed Makefiles and visualize in a List\n",
            "152\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gt5PiOlOfZFA"
      },
      "source": [
        "print(CWE_makefile_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtqjMdysQv0s"
      },
      "source": [
        "with open('CWE_makefile_dir_ls.pkl', 'wb') as fp:\n",
        "  pickle.dump (CWE_makefile_dir, fp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZBZ6U2bHWnw"
      },
      "source": [
        "## Summarize Preprocessed Data:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FiDTjDKkG-Vw"
      },
      "source": [
        "##Serialize & Store Preprocessed Data for next phase of the pipeline:\n",
        "\n",
        " >  *  1.   Use pycparser to extract ASTs from C code\n",
        " >  *  2.   Adapt Michael White's c_json.py code from pycparser Github repo to serialize ASTs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U0GR2dBxM8g6"
      },
      "source": [
        "> *   pycparser and Json serializing script for single file C programs submitted in programming competition "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Sm_Ep7PLqv6",
        "outputId": "74ba4bf7-1394-4cc6-91d6-32ff49e999b1"
      },
      "source": [
        "%%writefile c_json.py\n",
        "\n",
        "#------------------------------------------------------------------------------\n",
        "# pycparser: c_json.py\n",
        "#\n",
        "# by Michael White (@mypalmike)\n",
        "#\n",
        "# This example includes functions to serialize and deserialize an ast\n",
        "# to and from json format. Serializing involves walking the ast and converting\n",
        "# each node from a python Node object into a python dict. Deserializing\n",
        "# involves the opposite conversion, walking the tree formed by the\n",
        "# dict and converting each dict into the specific Node object it represents.\n",
        "# The dict itself is serialized and deserialized using the python json module.\n",
        "#\n",
        "# The dict representation is a fairly direct transformation of the object\n",
        "# attributes. Each node in the dict gets one metadata field referring to the\n",
        "# specific node class name, _nodetype. Each local attribute (i.e. not linking\n",
        "# to child nodes) has a string value or array of string values. Each child\n",
        "# attribute is either another dict or an array of dicts, exactly as in the\n",
        "# Node object representation. The \"coord\" attribute, representing the\n",
        "# node's location within the source code, is serialized/deserialized from\n",
        "# a Coord object into a string of the format \"filename:line[:column]\".\n",
        "#\n",
        "# Example TypeDecl node, with IdentifierType child node, represented as a dict:\n",
        "#     \"type\": {\n",
        "#         \"_nodetype\": \"TypeDecl\",\n",
        "#         \"coord\": \"c_files/funky.c:8\",\n",
        "#         \"declname\": \"o\",\n",
        "#         \"quals\": [],\n",
        "#         \"type\": {\n",
        "#             \"_nodetype\": \"IdentifierType\",\n",
        "#             \"coord\": \"c_files/funky.c:8\",\n",
        "#             \"names\": [\n",
        "#                 \"char\"\n",
        "#             ]\n",
        "#         }\n",
        "#     }\n",
        "#------------------------------------------------------------------------------\n",
        "#from __future__ import print_function\n",
        "\n",
        "import json\n",
        "import sys\n",
        "import re\n",
        "\n",
        "\n",
        "\n",
        "from pycparser import parse_file, c_ast\n",
        "from pycparser.plyparser import Coord\n",
        "\n",
        "\n",
        "RE_CHILD_ARRAY = re.compile(r'(.*)\\[(.*)\\]')\n",
        "RE_INTERNAL_ATTR = re.compile('__.*__')\n",
        "\n",
        "\n",
        "class CJsonError(Exception):\n",
        "    pass\n",
        "\n",
        "\n",
        "def memodict(fn):\n",
        "    \"\"\" Fast memoization decorator for a function taking a single argument \"\"\"\n",
        "    class memodict(dict):\n",
        "        def __missing__(self, key):\n",
        "            ret = self[key] = fn(key)\n",
        "            return ret\n",
        "    return memodict().__getitem__\n",
        "\n",
        "\n",
        "@memodict\n",
        "def child_attrs_of(klass):\n",
        "    \"\"\"\n",
        "    Given a Node class, get a set of child attrs.\n",
        "    Memoized to avoid highly repetitive string manipulation\n",
        "    \"\"\"\n",
        "    non_child_attrs = set(klass.attr_names)\n",
        "    all_attrs = set([i for i in klass.__slots__ if not RE_INTERNAL_ATTR.match(i)])\n",
        "    return all_attrs - non_child_attrs\n",
        "\n",
        "\n",
        "def to_dict(node):\n",
        "    \"\"\" Recursively convert an ast into dict representation. \"\"\"\n",
        "    klass = node.__class__\n",
        "\n",
        "    result = {}\n",
        "\n",
        "    # Metadata\n",
        "    result['_nodetype'] = klass.__name__\n",
        "\n",
        "    # Local node attributes\n",
        "    for attr in klass.attr_names:\n",
        "        result[attr] = getattr(node, attr)\n",
        "\n",
        "    # Coord object\n",
        "    if node.coord:\n",
        "        result['coord'] = str(node.coord)\n",
        "    else:\n",
        "        result['coord'] = None\n",
        "\n",
        "    # Child attributes\n",
        "    for child_name, child in node.children():\n",
        "        # Child strings are either simple (e.g. 'value') or arrays (e.g. 'block_items[1]')\n",
        "        match = RE_CHILD_ARRAY.match(child_name)\n",
        "        if match:\n",
        "            array_name, array_index = match.groups()\n",
        "            array_index = int(array_index)\n",
        "            # arrays come in order, so we verify and append.\n",
        "            result[array_name] = result.get(array_name, [])\n",
        "            if array_index != len(result[array_name]):\n",
        "                raise CJsonError('Internal ast error. Array {} out of order. '\n",
        "                    'Expected index {}, got {}'.format(\n",
        "                    array_name, len(result[array_name]), array_index))\n",
        "            result[array_name].append(to_dict(child))\n",
        "        else:\n",
        "            result[child_name] = to_dict(child)\n",
        "\n",
        "    # Any child attributes that were missing need \"None\" values in the json.\n",
        "    for child_attr in child_attrs_of(klass):\n",
        "        if child_attr not in result:\n",
        "            result[child_attr] = None\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "def to_json(node, **kwargs):\n",
        "    \"\"\" Convert ast node to json string \"\"\"\n",
        "    return json.dumps(to_dict(node), **kwargs)\n",
        "\n",
        "\n",
        "def file_to_dict(filename):\n",
        "    \"\"\" Load C file into dict representation of ast \"\"\"\n",
        "    ## ast = parse_file(filename, use_cpp=True) my addition of pycparser fakehead to allow for intraction with files\n",
        "    ast = parse_file(filename, use_cpp=True,\n",
        "            cpp_path='gcc',\n",
        "            cpp_args=['-E', r'-Iutils/fake_libc_include'])\n",
        "    return to_dict(ast)\n",
        "\n",
        "\n",
        "def file_to_json(filename, **kwargs):\n",
        "    \"\"\" Load C file into json string representation of ast \"\"\"\n",
        "     ## ast = parse_file(filename, use_cpp=True) my addition of pycparser fakehead to allow for intraction with files\n",
        "    ast = parse_file(filename, use_cpp=True,\n",
        "            cpp_path='gcc',\n",
        "            cpp_args=['-E', r'-Iutils/fake_libc_include'])\n",
        "    return to_json(ast, **kwargs)\n",
        "\n",
        "\n",
        "def _parse_coord(coord_str):\n",
        "    \"\"\" Parse coord string (file:line[:column]) into Coord object. \"\"\"\n",
        "    if coord_str is None:\n",
        "        return None\n",
        "\n",
        "    vals = coord_str.split(':')\n",
        "    vals.extend([None] * 3)\n",
        "    filename, line, column = vals[:3]\n",
        "    return Coord(filename, line, column)\n",
        "\n",
        "\n",
        "def _convert_to_obj(value):\n",
        "    \"\"\"\n",
        "    Convert an object in the dict representation into an object.\n",
        "    Note: Mutually recursive with from_dict.\n",
        "    \"\"\"\n",
        "    value_type = type(value)\n",
        "    if value_type == dict:\n",
        "        return from_dict(value)\n",
        "    elif value_type == list:\n",
        "        return [_convert_to_obj(item) for item in value]\n",
        "    else:\n",
        "        # String\n",
        "        return value\n",
        "\n",
        "\n",
        "def from_dict(node_dict):\n",
        "    \"\"\" Recursively build an ast from dict representation \"\"\"\n",
        "    class_name = node_dict.pop('_nodetype')\n",
        "\n",
        "    klass = getattr(c_ast, class_name)\n",
        "\n",
        "    # Create a new dict containing the key-value pairs which we can pass\n",
        "    # to node constructors.\n",
        "    objs = {}\n",
        "    for key, value in node_dict.items():\n",
        "        if key == 'coord':\n",
        "            objs[key] = _parse_coord(value)\n",
        "        else:\n",
        "            objs[key] = _convert_to_obj(value)\n",
        "\n",
        "    # Use keyword parameters, which works thanks to beautifully consistent\n",
        "    # ast Node initializers.\n",
        "    return klass(**objs)\n",
        "\n",
        "\n",
        "def from_json(ast_json):\n",
        "    \"\"\" Build an ast from json string representation \"\"\"\n",
        "    return from_dict(json.loads(ast_json))\n",
        "\n",
        "\n",
        "#------------------------------------------------------------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    if len(sys.argv) > 1:\n",
        "        # Some test code...\n",
        "        # Do trip from C -> ast -> dict -> ast -> json, then print.\n",
        "        ast_dict = file_to_dict(sys.argv[1])\n",
        "        ast = from_dict(ast_dict)\n",
        "        json_object = to_json(ast, sort_keys=True, indent=4)\n",
        "        print(json_object)\n",
        "        with open(sys.argv[1][:-2]+ \".json\", \"w\") as outfile:\n",
        "          outfile.write(json_object)\n",
        "        ## little adjustment to save to a file names almost as input file. The minus 2 for \".c\"\n",
        "    else:\n",
        "        print(\"Please provide a filename as argument\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing c_json.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifcib-RSFWAA"
      },
      "source": [
        "##i.) Explore Serializing of Main Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p6NU1_H9SOyE",
        "outputId": "e6070bf7-39b9-4f4f-fa21-72f591e1cebd"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "C\t\t\t      juliet_dataset_CWE_testcases_paths_ls.pkl\n",
            "c_compiled_ls.pkl\t      juliet_dataset_ls.pkl\n",
            "c_json.py\t\t      Juliet_Test_Suite_v1.3_for_C_Cpp.zip\n",
            "cpp_compiled_ls.pkl\t      ProgramData\n",
            "CWE_makefile_dir_ls.pkl       programs.tar.gz\n",
            "data_acquisition\t      raw_data.tar\n",
            "decodable_submisisons_ls.pkl  sample_data\n",
            "drive\t\t\t      submissions_ls.pkl\n",
            "juliet_dataset_CWE_ls.pkl     submissions_tasks_ls.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0Mo7L5mSZxE"
      },
      "source": [
        "#Test AST json generating script \n",
        "!python3 c_json.py /content/ProgramData/1/1076.c"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r73PUbfTSo4i"
      },
      "source": [
        "#Check that json ast (1076.json) was created in addtion to the stdout priprint \n",
        "!ls ./ProgramData/1/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_7_Wp5DUMl-",
        "outputId": "4eeedb40-02d2-413f-9777-e0b999ac685b"
      },
      "source": [
        "#Generate the rest of the json ASTs from the Programming Competition submissions \n",
        "for i in range(len(compiled_c_code)):\n",
        "    subprocess.run([\"python3\", \"c_json.py\", compiled_c_code[i]])\n",
        "print('Done generating json ASTs. Verify with ls cmd')  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done generating json ASTs. Verify with ls cmd\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FAjYnMl8UrW2",
        "outputId": "c35c5cd9-1e93-4040-ed29-794304cf09ba"
      },
      "source": [
        "#Verify success of json generating script\n",
        "programming_competition_c_ast_jsons = []\n",
        "paths = Path('./ProgramData').glob('**/*.json')\n",
        "for path in paths:\n",
        "  programming_competition_c_ast_jsons.append(str(path))\n",
        "  # str because path is an object not string\n",
        "print(\"Generated {} jsons of C ASTs from the programming submissions\".format(len(programming_competition_c_ast_jsons)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated 36594 jsons of C ASTs from the programming submissions\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5yWLKho_CXW"
      },
      "source": [
        "print(programming_competition_c_ast_jsons)\n",
        "print('\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_E4XS5SqVPtG"
      },
      "source": [
        "#check for json ASTs in  ProgramData subdirectories e.g. ProgramData/1/\n",
        "!ls ./ProgramData/1/ "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yq_6KNJGJCMc"
      },
      "source": [
        "with open('programming_competition_c_ast_jsons_ls.pkl', 'wb') as fp:\n",
        "  pickle.dump (programming_competition_c_ast_jsons, fp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yMm8iX2idvI7",
        "outputId": "229067fe-5558-44b4-c2a4-f14b7767a19f"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlQZFWaVW7In"
      },
      "source": [
        "##Create archive of Preprocessed data for use in next phase of pipeline\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7ng8JLxEUZk"
      },
      "source": [
        "!rm -rf data_acquisition/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYtjKTxoXtBX"
      },
      "source": [
        "#create folder to store preprocessed data\n",
        "!mkdir preprocessed_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2hMEcBy2YmA_",
        "outputId": "1cc8e77f-2ce1-48ab-ba21-b6fbe4ae8b82"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DbHRVo9ICqB-",
        "outputId": "e8f73224-13bd-4017-baf4-175a04ecbef4"
      },
      "source": [
        "#Move preprocessed data and pickled meta data to folder for compression and storage for use in next part of the pipeline\n",
        "%cp -r C c_compiled_ls.pkl c_json.py cpp_compiled_ls.pkl CWE_makefile_dir_ls.pkl decodable_submisisons_ls.pkl juliet_dataset_CWE_ls.pkl juliet_dataset_CWE_testcases_paths_ls.pkl juliet_dataset_ls.pkl Juliet_Test_Suite_v1.3_for_C_Cpp.zip ProgramData programming_competition_c_ast_jsons_ls.pkl submissions_ls.pkl submissions_tasks_ls.pkl preprocessed_data/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: target 'preprocessed_data/' is not a directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HogebfPWU-MA"
      },
      "source": [
        "#zipping processed juliet dataset and metadata\n",
        "shutil.make_archive('preprocessed_data','tar','/content/','preprocessed_data')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cy9DhmbX5ns5"
      },
      "source": [
        "#Verify tarball of raw-data\n",
        "temp_archive = []\n",
        "with tarfile.open('preprocessed_data', 'r') as green:\n",
        "  for member in green:\n",
        "    if member.isdir() and member.name.count ('/') > 0:\n",
        "     # The '/' > 0 is to ensure the root directory is ignored \n",
        "       print(member.name) \n",
        "    if member.isfile():\n",
        "     temp_archive.append (member.name)\n",
        "print(\"\\n Number of files in preprocessed_data tarball for export to googledrive for use later {0}\".format(len(temp_archive)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iX_8-VHC1ex7"
      },
      "source": [
        "!cp preprocessed_data.tar \"/content/drive/My Drive/colab_root/compchem-compsci-shared-rep/processed/\""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}